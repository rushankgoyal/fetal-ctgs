{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q70R5abXmCo"
      },
      "source": [
        "import numpy as np\n",
        "np.warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDYMyhf1C4Js",
        "outputId": "afbb5c50-7b5a-463a-89f5-1c603b3ec71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "import pandas as pd\n",
        "traindf = pd.read_csv('/content/aicrowdcrdiotrain.csv')\n",
        "traindf.drop(columns=['UC'],inplace=True)\n",
        "testdf = pd.read_csv('/content/aicrowdcrdiotest.csv')\n",
        "testdf.drop(columns=['UC'],inplace=True)\n",
        "print(traindf)\n",
        "print(testdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        LBE     LB    AC   FM  ASTV  ...   Mean  Median  Variance  Tendency  NSP\n",
            "0     135.0  135.0   8.0  2.0  60.0  ...  142.0   145.0       7.0       0.0    1\n",
            "1     133.0  133.0   0.0  4.0  60.0  ...  122.0   130.0      14.0       1.0    1\n",
            "2     135.0  135.0  10.0  2.0  60.0  ...  143.0   146.0       6.0       0.0    1\n",
            "3     120.0  120.0   3.0  1.0  56.0  ...  125.0   126.0       3.0       0.0    1\n",
            "4     132.0  132.0   6.0  0.0  27.0  ...  146.0   149.0      18.0       1.0    1\n",
            "...     ...    ...   ...  ...   ...  ...    ...     ...       ...       ...  ...\n",
            "1695  123.0  123.0   3.0  0.0  33.0  ...  122.0   127.0      39.0       0.0    1\n",
            "1696  122.0  122.0   1.0  0.0  16.0  ...  113.0   116.0      21.0       0.0    1\n",
            "1697  139.0  139.0   0.0  6.0  75.0  ...  139.0   141.0       2.0       1.0    2\n",
            "1698  144.0  144.0   2.0  0.0  32.0  ...  150.0   150.0       8.0       0.0    1\n",
            "1699  137.0  137.0   0.0  0.0  74.0  ...  141.0   142.0       1.0       0.0    3\n",
            "\n",
            "[1700 rows x 23 columns]\n",
            "       LBE     LB   AC   FM  ASTV  ...   Mode   Mean  Median  Variance  Tendency\n",
            "0    135.0  135.0  0.0  0.0  68.0  ...  137.0  136.0   138.0       0.0       0.0\n",
            "1    120.0  120.0  0.0  4.0  57.0  ...  125.0  123.0   124.0       1.0       0.0\n",
            "2    133.0  133.0  0.0  1.0  61.0  ...  128.0  103.0   116.0      70.0       0.0\n",
            "3    125.0  125.0  6.0  4.0  19.0  ...  133.0  131.0   133.0       5.0      -1.0\n",
            "4    138.0  138.0  0.0  0.0  34.0  ...  148.0  142.0   146.0       9.0       1.0\n",
            "..     ...    ...  ...  ...   ...  ...    ...    ...     ...       ...       ...\n",
            "421  125.0  125.0  0.0  0.0  62.0  ...  129.0  117.0   125.0      32.0       1.0\n",
            "422  134.0  134.0  5.0  1.0  53.0  ...  143.0  133.0   140.0      29.0       1.0\n",
            "423  115.0  115.0  3.0  0.0  22.0  ...  112.0  118.0   117.0      11.0      -1.0\n",
            "424  126.0  126.0  0.0  0.0  34.0  ...  133.0  132.0   134.0       2.0       1.0\n",
            "425  132.0  132.0  2.0  3.0  58.0  ...  133.0  135.0   134.0       3.0       0.0\n",
            "\n",
            "[426 rows x 22 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he0uWj2GDTsK",
        "outputId": "535b6632-6cf3-4d3e-a494-06b524134127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "y = traindf.iloc[:,-1]\n",
        "X = traindf.iloc[:,:-1]\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "#import autosklearn.classification\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "\n",
        "#automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=120,per_run_time_limit=30)\n",
        "\n",
        "dtreeclf = tree.DecisionTreeClassifier()\n",
        "abcclf = AdaBoostClassifier(tree.DecisionTreeClassifier(),n_estimators=150,random_state=0)\n",
        "rfclf = RandomForestClassifier(random_state=0)\n",
        "rfclf2 = RandomForestClassifier(random_state=0,)\n",
        "rfclf3 = RandomForestClassifier(random_state=0)\n",
        "mlpclf = MLPClassifier(random_state=0, max_iter=500)\n",
        "svmclf = svm.SVC()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "estimators = [('abc', abcclf),('mlp', mlpclf),('rf3', rfclf3),('rf2',rfclf2),('xgb', xgb)] #('svm',svmclf)\n",
        "rfstack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# voteclf = VotingClassifier(estimators=[('dt', dtreeclf), ('abc', abcclf), ('rf', rfclf)], voting='hard')\n",
        "\n",
        "# rfvoteclf = VotingClassifier(estimators=[('rf1', rfclf), ('rf2', rfclf2), ('rf3', rfclf3)], voting='hard')\n",
        "\n",
        "# #estimators = [('ridge', RidgeCV()),('lasso', LassoCV(random_state=42)),('svr', SVR(C=1, gamma=1e-6))]\n",
        "\n",
        "# voteparams = {'dt__max_depth': [30, 100], 'rf__n_estimators': [20, 200]}\n",
        "# votegrid = GridSearchCV(estimator=voteclf, param_grid=voteparams, cv=5)\n",
        "\n",
        "# rfparams = {'rf2__n_estimators': [30, 300], 'rf3__n_estimators': [20, 300], 'abc__n_estimators': [120,350]}\n",
        "# rfgrid = GridSearchCV(estimator=rfstack, param_grid=rfparams, cv=5)\n",
        "\n",
        "models = [abcclf,rfclf,rfclf2,rfclf3,rfstack,xgb]\n",
        "\n",
        "#X.values.reshape(1700,23)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n",
        "\n",
        "for model in models:\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred = model.predict(X_val)\n",
        "  print(accuracy_score(y_val,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9607843137254902\n",
            "0.9411764705882353\n",
            "0.9411764705882353\n",
            "0.9411764705882353\n",
            "0.9607843137254902\n",
            "0.9529411764705882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reLOXsAHfwgq",
        "outputId": "d6f60e90-0fb5-4bf5-933c-fdc20a017e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "rfstack.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(cv=None,\n",
              "                   estimators=[('abc',\n",
              "                                AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                                         class_weight=None,\n",
              "                                                                                         criterion='gini',\n",
              "                                                                                         max_depth=None,\n",
              "                                                                                         max_features=None,\n",
              "                                                                                         max_leaf_nodes=None,\n",
              "                                                                                         min_impurity_decrease=0.0,\n",
              "                                                                                         min_impurity_split=None,\n",
              "                                                                                         min_samples_leaf=1,\n",
              "                                                                                         min_samples_split=2,\n",
              "                                                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                                                         presort...\n",
              "                                              seed=None, silent=None,\n",
              "                                              subsample=1, verbosity=1))],\n",
              "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=100,\n",
              "                                                      multi_class='auto',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='lbfgs',\n",
              "                                                      tol=0.0001, verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL4NRSBenBwE",
        "outputId": "1e2be60c-8a7a-4c08-c929-a6ed7e73b2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "print(testdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       LBE     LB   AC   FM  ASTV  ...   Mode   Mean  Median  Variance  Tendency\n",
            "0    135.0  135.0  0.0  0.0  68.0  ...  137.0  136.0   138.0       0.0       0.0\n",
            "1    120.0  120.0  0.0  4.0  57.0  ...  125.0  123.0   124.0       1.0       0.0\n",
            "2    133.0  133.0  0.0  1.0  61.0  ...  128.0  103.0   116.0      70.0       0.0\n",
            "3    125.0  125.0  6.0  4.0  19.0  ...  133.0  131.0   133.0       5.0      -1.0\n",
            "4    138.0  138.0  0.0  0.0  34.0  ...  148.0  142.0   146.0       9.0       1.0\n",
            "..     ...    ...  ...  ...   ...  ...    ...    ...     ...       ...       ...\n",
            "421  125.0  125.0  0.0  0.0  62.0  ...  129.0  117.0   125.0      32.0       1.0\n",
            "422  134.0  134.0  5.0  1.0  53.0  ...  143.0  133.0   140.0      29.0       1.0\n",
            "423  115.0  115.0  3.0  0.0  22.0  ...  112.0  118.0   117.0      11.0      -1.0\n",
            "424  126.0  126.0  0.0  0.0  34.0  ...  133.0  132.0   134.0       2.0       1.0\n",
            "425  132.0  132.0  2.0  3.0  58.0  ...  133.0  135.0   134.0       3.0       0.0\n",
            "\n",
            "[426 rows x 22 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN737tnTFSIZ"
      },
      "source": [
        "submission = pd.DataFrame(rfstack.predict(testdf))\n",
        "submission.to_csv('/content/submission.csv',header=['NSP'],index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCGfl7H8OMSm",
        "outputId": "79c2cd0e-4fd6-4b1e-92e6-e1e46891307d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# !apt-get install swig -y\n",
        "# !pip install Cython numpy\n",
        "\n",
        "# sometimes you have to run the next command twice on colab\n",
        "# I haven't figured out why\n",
        "!pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting auto-sklearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/06/7b01155e9d507b173a4ee64a357957e04965c651cc1c3ff9ff3715930713/auto-sklearn-0.10.0.tar.gz (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (50.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.12.0)\n",
            "Requirement already satisfied: distributed in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.25.3)\n",
            "Collecting lockfile\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Collecting pandas<1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 10.3MB/s \n",
            "\u001b[?25hCollecting liac-arff\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/43/73944aa5ad2b3185c0f0ba0ee6f73277f2eb51782ca6ccf3e6793caf209a/liac-arff-2.5.0.tar.gz\n",
            "Collecting ConfigSpace<0.5,>=0.4.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/e5/0852c3f956ea7f16770c7e8038f78a6385bfd0ea2c9b2fa20de9a917f327/ConfigSpace-0.4.15.tar.gz (964kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 33.5MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynisher>=0.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/10/23/23480e4e6ad55bc5f31bcc3c4ad48a3aeb33a02aff46c174670be91be104/pynisher-0.6.1.tar.gz\n",
            "Collecting pyrfr<0.9,>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/0f/4d7e42a9dfef3a1898e03cffa8f1cfcd1f96507d718808b2db584c6f8401/pyrfr-0.8.0.tar.gz (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 38.3MB/s \n",
            "\u001b[?25hCollecting smac<0.14,>=0.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/72/075f1c8f90bcd169e316ab5b92ac04fea347b3b5ab2ee08ae04220dd13ce/smac-0.13.0.tar.gz (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: toolz>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (0.11.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (1.15.0)\n",
            "Requirement already satisfied: tblib in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (2.2.2)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.6/dist-packages (from distributed->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0->auto-sklearn) (2.8.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.21)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.16)\n",
            "Collecting lazy_import\n",
            "  Downloading https://files.pythonhosted.org/packages/44/2e/5378f9b9cbc893826c2ecb022646c97ece9efbaad351adf89425fff33990/lazy_import-0.2.2.tar.gz\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed->auto-sklearn) (1.0.1)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.15-cp36-cp36m-linux_x86_64.whl size=2888425 sha256=a06f207baaae8294d888a57880e87edb9cc305077ba0734eecfa5881495b366e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/9c/a6/d749d412a09687bc9ccf52d2e2327d9bef2c0d0d8fb07905cb\n",
            "Successfully built ConfigSpace\n",
            "Building wheels for collected packages: auto-sklearn, liac-arff, pynisher, pyrfr, smac, lazy-import\n",
            "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.10.0-cp36-none-any.whl size=4302075 sha256=ad4fc6012dd24792b281a096baca9c2898a62058d42c94d2b39aaf15cfcd69be\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/97/20/8edf157c4cfb9ac276d1d3291217e0e2cb73fec6766574674d\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-cp36-none-any.whl size=11734 sha256=1ebf3c1918faa2d371239a0759f6ad5a18e126fca10de5bdf3b7a4ff75f8b3e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/8d/b4/8bfce5beea9a3496cc15b24961876adb7b6e2912ff09164179\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.1-cp36-none-any.whl size=4755 sha256=8181e972e7bda533b096d673d0da5e14b14c1ef4b5ddb262f7c47bb04a2a3183\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/2d/34/e53a6a82c0dfb4a6f7721fc3e079dd588ba19d4978bdb2d493\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyrfr\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pyrfr\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-0.13.0-cp36-none-any.whl size=245193 sha256=036bc8f6c54a5b246273a18f83686284600ab65dc34c7ed0c06643fa642d798f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/08/34/0034057e1331739c63a45e3ac5c566432f7b5749e6fbb1052c\n",
            "  Building wheel for lazy-import (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lazy-import: filename=lazy_import-0.2.2-py2.py3-none-any.whl size=16486 sha256=43742d21f767f403738d04bc8859f5bd9d0b24a170a69941fa82772c08665e30\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/b0/b5/8c7e6810aee14bc4ed4a542ce56e744126263bf4f4825a9094\n",
            "Successfully built auto-sklearn liac-arff pynisher smac lazy-import\n",
            "Failed to build pyrfr\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: lockfile, pandas, liac-arff, ConfigSpace, pynisher, pyrfr, lazy-import, smac, auto-sklearn\n",
            "  Found existing installation: pandas 1.1.2\n",
            "    Uninstalling pandas-1.1.2:\n",
            "      Successfully uninstalled pandas-1.1.2\n",
            "    Running setup.py install for pyrfr ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-rl1qb3kd/pyrfr/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-rl1qb3kd/pyrfr/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-40ajtibn/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}